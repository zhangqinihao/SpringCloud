分布式系统面临的问题
复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免地失败。


一般情况对于服务依赖的保护主要有3中解决方案：
 
（1）熔断模式：这种模式主要是参考电路熔断，如果一条线路电压过高，保险丝会熔断，防止火灾。
     放到我们的系统中，如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，
     不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。
 
（2）隔离模式：这种模式就像对系统请求按类型划分成一个个小岛的一样，当某个小岛被火少光了，不会影响到其他的小岛。
     例如可以对不同类型的请求使用线程池来资源隔离，每种类型的请求互不影响，如果一种类型的请求线程资源耗尽，
     则对后续的该类型请求直接返回，不再调用后续资源。这种模式使用场景非常多，例如将一个服务拆开，
     对于重要的服务使用单独服务器来部署，再或者公司最近推广的多中心。
 
（3）限流模式：上述的熔断模式和隔离模式都属于出错后的容错处理机制，而限流模式则可以称为预防模式。
     限流模式主要是提前对各个类型的请求设置最高的QPS阈值，若高于设置的阈值则对该请求直接返回，
     不再调用后续资源。这种模式不能解决服务依赖的问题，只能解决系统整体资源分配问题，
     因为没有被限流的请求依然有可能造成雪崩效应。
     
============================================================================================================
服务降级
服务器忙，请稍候再试，不让客户端等待并立刻返回一个友好提示，fallback

哪些情况会触发降级?
程序运行异常
超时
服务熔断触发服务降级
线程池/信号量打满也会导致服务降级



服务熔断?
类比保险丝达到最大服务访问后，
直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示

服务的降级->进而熔断->恢复调用链路

服务限流 ?
秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟N个，有序进行
项目 cloud-provider-hystrix-payment8001  7001  


成功 http://localhost:8001/payment/hystrix/ok/31

失败 http://localhost:8001/payment/hystrix/timeout/31

以上述为根基平台，从正确->错误->降级熔断->恢复
=======================================================================
开启Jmeter，来20000个并发压死8001，20000个请求都去访问paymentInfo_TimeOut服务

http://jmeter.apache.org/download_jmeter.cgi
下载 Binaries zip（win版本）
找到jmeter下的bin目录，打开jmeter.properties 文件

第三十七行（新版39行）修改为

language=zh_CN

去掉前面的#，以后打开就是中文界面了

看演示结果
两个都在自己转圈圈
结论:上面还是服务提供者8001自己测试，
假如此时外部的消费者80也来访问，那消费者只能干等，
最终导致消费端80不满意，服务端8001直接被拖死
====================================
新建 
cloud-consumer-feign-hystrix-order80

正常测试 http://localhost/consumer/payment/hystrix/ok/31
2W个线程压8001
http://localhost/consumer/payment/hystrix/timeout/31
消费者80，呜呜呜


故障现象和导致原因
8001同一层次的其他接口服务被困死，因为tomcat线程里面的工作线程已经被挤占完毕
80此时调用8001，客户端访问响应缓慢，转圈圈
==================================================

超时导致服务器变慢（转圈）  超时不再等待
出错（宕机或程序运行出错） 出错要有兜底

解决：
对方服务（8001）超时了，调用者（80）不能一直卡死等待，必须有服务降级
对方服务（8001）down机了，调用者（80）不能一直卡死等待，必须有服务降级
对方服务（8001）OK，调用者（80）自己出故障或有自我要求（自己的等待时间小于服务提供者），自己处理降级

====
服务降级
  
@HystrixCommand注解 见Hystrix8001 设置自身调用超时时间的峰值，峰值内可以正常运行，超过了需要有兜底的方法处理，作服务降级fallback 

@HystrixCommand报异常后如何处理
一旦调用服务方法失败并抛出了错误信息后，会自动调用@HystrixCommand标注好的fallbackMethod调用类中的指定方法


添加新注解@EnableCircuitBreaker
测试 http://localhost:8001/payment/hystrix/timeout/31  测试抛异常
     http://localhost:8001/payment/hystrix/timeoutok/31 测试ok
     
80订单微服务，也可以更好的保护自己，自己也依样画葫芦进行客户端降级保护 ***一般都是降级放80
其题外话：我们自己配置过的热部署方式对java代码的改动明显，但对@HystrixCommand内属性的修改建议重启微服务

yml
feign:
  hystrix:
    enabled: true #如果处理自身的容错就开启。开启方式与生产端不一样。
主启动类
@EnableHystrix   这个跟是生产者启动类注解不一样

业务
@HystrixCommand注解 见Hystrix8001 设置自身调用超时时间的峰值，峰值内可以正常运行，超过了需要有兜底的方法处理，作服务降级fallback 

@HystrixCommand报异常后如何处理
一旦调用服务方法失败并抛出了错误信息后，会自动调用@HystrixCommand标注好的fallbackMethod调用类中的指定方法

测试
http://localhost/consumer/payment/hystrix/timeout/31  失败
http://localhost:8001/payment/hystrix/timeoutok/2   成功


目前问题
每个业务方法对应一个兜底的方法，代码膨胀   一个一个写兜底得方法是傻逼行为
解决 :统一和自定义的分开
见OrderHystrixquanjutongyongController
@DefaultProperties(defaultFallback = "")
测试
http://localhost/tongyong/consumer/payment/hystrix/timeout/31  全局


http://localhost/tongyong/consumer/payment/hystrix/timeoutok/31 自定义

全局fallback方法不用加参数
==============================================================================

  控制层一个一个调用指定服务名称 万一服务宕机怎么办

jieouController
 在服务层配置全局降级方法
本次案例服务降级处理是在客户端80实现完成的，
与服务端8001没有关系，
只需要为Feign客户端定义的接口添加一个服务降级处理的实现类即可实现解耦

未来我们要面对的异常
运行：代码错误
超时
宕机

根据cloud-consumer-feign-hystrix-order80已经有的PaymentHystrixService接口
，重新新建一个类（PaymentFallbackService）实现该接口，统一为接口里面的方法进行异常处理
http://localhost/jieou/consumer/payment/hystrix/ok/1
关闭生产者 测试

=======================================================================
断路器  一句话就是家里保险丝





